# üì¶ SmartWaste API

**Sistema de gesti√≥n inteligente de residuos urbanos**  
Este backend basado en FastAPI permite gestionar usuarios, sensores, contenedores, rutas y lecturas para optimizar la recolecci√≥n de residuos urbanos mediante IoT.

---

## üöÄ Clonaci√≥n y Ejecuci√≥n del Proyecto

### üîß Requisitos previos

- Python 3.10 o superior  
- MySQL instalado y corriendo (o Docker para usar el contenedor)  
- Git  
- pip/venv o [Poetry](https://python-poetry.org/) (recomendado)

---

### üì• Clonar el repositorio

```bash
git clone https://github.com/JoseLuisCM663/SmartWasteApi.git
cd SmartWasteApi
```

---

### üêç Configurar entorno virtual (opcional pero recomendado)

**Con `venv`:**

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

---

### üì¶ Instalar dependencias

**Con pip:**

```bash
pip install -r requirements.txt
```

---

### ‚öôÔ∏è Configuraci√≥n del entorno

Copiar archivo `.env.example` a `.env`:

```bash
cp .env.example .env
```

Modificar las variables en el archivo `.env`:

```env
DB_USERNAME=root
DB_PASSWORD=12345678
DB_HOST=localhost
DB_PORT=3306
DB_NAME=smartwaste
SECRET_KEY=ejemplo
ALGORITHM=HS256
```

---

### üõ¢Ô∏è Configurar base de datos

1. Crear base de datos:


```sql
CREATE DATABASE smartwaste;
```

---

### üöÄ Ejecutar la aplicaci√≥n

```bash
uvicorn app.main:app --reload
```

La aplicaci√≥n estar√° disponible en:  
‚û°Ô∏è [http://localhost:8000](http://localhost:8000)

---

### üê≥ Ejecuci√≥n con Docker

Construir y ejecutar los contenedores:

```bash
docker-compose up --build
```

La aplicaci√≥n estar√° disponible en:  
‚û°Ô∏è [http://localhost:8000](http://localhost:8000)

---

## üìö Documentaci√≥n de la API

- Swagger UI: [http://localhost:8000/docs](http://localhost:8000/docs)  
- Redoc: [http://localhost:8000/redoc](http://localhost:8000/redoc)


---

## üõ†Ô∏è Estructura del Proyecto

```
app/
‚îú‚îÄ‚îÄ config/        # Configuraciones principales
‚îú‚îÄ‚îÄ crud/          # Operaciones CRUD para la base de datos
‚îú‚îÄ‚îÄ models/        # Modelos de SQLAlchemy
‚îú‚îÄ‚îÄ schemas/       # Esquemas Pydantic para validaci√≥n
‚îú‚îÄ‚îÄ routes/        # Endpoints para acceso a las funciones
‚îú‚îÄ‚îÄ utils/         # 
‚îú‚îÄ‚îÄ main.py         # Rutas principales
‚îî‚îÄ‚îÄ database.py    # Configuraci√≥n de la base de datos
```

---
#  Seeder de Datos

Este repositorio incluye scripts para poblar la base de datos de **SmartWasteAPI** con datos de prueba.

---

## üöÄ Funcionalidades incluidas

### 1. Seeder principal (`config/seeder.py`)

Este script inserta datos iniciales en las siguientes tablas:

- ‚úÖ **Usuarios** (Admin, Usuario, Chofer)
- ‚úÖ **Rutas** de recolecci√≥n
- ‚úÖ **Contenedores** (asociados a rutas)
- ‚úÖ **Sensores** (asociados a contenedores)
- ‚úÖ **Relaci√≥n Usuario-Ruta**

#### ‚ñ∂Ô∏è Uso

```bash
python config/seeder.py --usuarios 3 --rutas 2 --contenedores 2 --sensores 2 --seed 42
```

#### üìå Argumentos

| Par√°metro        | Descripci√≥n                               | Valor por defecto |
|------------------|--------------------------------------------|-------------------|
| `--usuarios`     | N√∫mero de usuarios a crear                 | 3                 |
| `--rutas`        | N√∫mero de rutas                            | 2                 |
| `--contenedores` | N√∫mero de contenedores                     | 2                 |
| `--sensores`     | N√∫mero de sensores                         | 2                 |
| `--seed`         | Semilla para datos aleatorios reproducibles | Opcional          |

---

### 2. Generador de Lecturas de Sensor

Genera lecturas simuladas para sensores.

#### üß™ Uso

```python
from crud.seeder import generar_lecturas_sensor

generar_lecturas_sensor(sensor_id=1, cantidad=100, valor_min=10, valor_max=90)
```

#### üîß Par√°metros

- `sensor_id`: ID del sensor a asociar las lecturas
- `cantidad`: N√∫mero de lecturas a generar
- `valor_min`: Valor m√≠nimo de lectura
- `valor_max`: Valor m√°ximo de lectura
- `intervalo_minutos`: (opcional) intervalo entre lecturas

---

### 3. Generador de Bit√°coras de Recolecci√≥n

Inserta bit√°coras con datos asociados a rutas y contenedores.

#### üßæ Uso

```python
from crud.seeder import poblar_bitacoras
from app.database import SessionLocal

db = SessionLocal()
poblar_bitacoras(db, cantidad=10)
```

---

## üóÇ Estructura de Carpetas

```
config/
  ‚îî‚îÄ‚îÄ seeder.py           # Seeder principal
crud/
  ‚îî‚îÄ‚îÄ seeder.py           # Funciones de utilidad (lecturas, bit√°coras)
```
# üßπ Preprocesamiento y Limpieza de Datos - SmartWasteApi

Este m√≥dulo forma parte del backend de **SmartWasteApi**, encargado del **ETL (Extracci√≥n, Transformaci√≥n y Carga)** de datos recolectados por sensores y bit√°coras del sistema de gesti√≥n inteligente de residuos.

## üìÇ Funcionalidades implementadas

### 1. `exportar_lecturas_sensor(sensor_id, ruta_csv, db)`

Exporta las lecturas de un sensor espec√≠fico a un archivo CSV, siguiendo los pasos del proceso ETL:

- **Extracci√≥n:** Consultas a la base de datos con SQLAlchemy por `Sensor_Id`.
- **Transformaci√≥n:** Se aplican t√©cnicas de:
  - Conversi√≥n y ordenaci√≥n temporal (`datetime`)
  - Eliminaci√≥n de duplicados
  - Filtrado y clipping de valores (0-100)
  - Resampleo a intervalos regulares (5 minutos)
  - Interpolaci√≥n lineal para valores faltantes
  - Redondeo de valores
  - Creaci√≥n de variables adicionales: `Hora`, `D√≠a de la semana`
- **Carga:** Generaci√≥n y guardado de un archivo `.csv` limpio y estructurado.

### 2. `etl_bitacoras(db)`

Realiza la limpieza y exportaci√≥n de datos de dos tablas de bit√°coras:

- **Bit√°cora de Recolecci√≥n:**
  - Se excluyen registros sin fecha o ruta v√°lida
  - Se filtran valores at√≠picos en duraci√≥n (>500)
  - Se imputan valores por defecto para campos nulos (ej. observaciones)
- **Bit√°cora de Contenedor:**
  - Se validan fechas y IDs de contenedores
  - Se eliminan valores de porcentaje de llenado fuera de rango (0-100)
  - Se etiquetan estados desconocidos

Retorna dos `DataFrames` limpios listos para an√°lisis o exportaci√≥n.

## üöÄ Endpoints disponibles

### `GET /exportar-sensor/?sensor_id=ID`

- Ejecuta `exportar_lecturas_sensor`
- Devuelve un archivo `.csv` limpio con las lecturas del sensor especificado

### `GET /exportar-bitacoras/`

- Ejecuta `etl_bitacoras`
- Devuelve un archivo `.zip` con los siguientes CSVs:
  - `bitacora_recoleccion_etl.csv`
  - `bitacora_contenedor_etl.csv`

## üìå Ubicaci√≥n del c√≥digo

- L√≥gica principal de ETL: `app/utils/etl_export.py`
- Rutas de exportaci√≥n: `app/routers/exportar.py`

## üõ† Requisitos

- Pandas
- Numpy
- SQLAlchemy
- FastAPI
- Zipfile (m√≥dulo est√°ndar de Python)

## üìÅ Ejemplo de uso

```bash
curl -X GET "http://localhost:8000/exportar-sensor/?sensor_id=1" -o lecturas_sensor_1.csv

curl -X GET "http://localhost:8000/exportar-bitacoras/" -o bitacoras_etl.zip
```

## üìà Objetivo del m√≥dulo

Garantizar datos limpios, consistentes y listos para an√°lisis de comportamiento, modelos predictivos o visualizaciones, reduciendo errores por datos at√≠picos o faltantes.

---
# Modelo de An√°lisis Supervisado (ML) - Clasificaci√≥n de Rutas

Este m√≥dulo implementa un **modelo supervisado** para clasificar rutas de recolecci√≥n como **Eficientes** o **Ineficientes**, utilizando datos hist√≥ricos de bit√°coras de recolecci√≥n y contenedores.

---

## Estructura de la API

Se exponen los siguientes endpoints en FastAPI:

### Entrenamiento del modelo

```
POST /ml/entrenar/
```

**Descripci√≥n:**
Entrena un modelo de clasificaci√≥n usando los CSV de bit√°coras de recolecci√≥n y contenedores.

**C√≥digo de ejemplo:**

```python
resultado = ml_model.entrenar_modelo_bitacoras(
    "public/bitacora_recoleccion_etl.csv",
    "public/bitacora_contenedor_etl.csv"
)
```

**Respuesta esperada:**

```json
{
  "mensaje": "Modelo entrenado y guardado",
  "accuracy": 0.85,
  "f1_score": 0.84,
  "reporte": "Classification report completo..."
}
```

---

### Predicci√≥n de rutas

```
GET /ml/predecir/?bitacora_id={id}
```

**Descripci√≥n:**
Predice si una ruta de recolecci√≥n (bit√°cora) es **Eficiente** o **Ineficiente**, usando los datos de BitacoraRecoleccion y BitacoraContenedor.

**C√≥digo de ejemplo:**

```python
resultado = ml_model.predecir_ruta_por_bitacora(bitacora_id, db)
```

**Respuesta esperada:**

```json
{
  "bitacora_id": 123,
  "prediccion": "Eficiente",
  "features": {
    "Tiempo_Duracion": 90,
    "Cantidad_Contenedores": 5,
    "Porcentaje_Llenado": 0.85,
    "Recolectado": 1.0
  }
}
```

---

## Proceso de Entrenamiento

1. **Carga de datos:** Se leen los archivos CSV de bit√°coras de recolecci√≥n y contenedores.
2. **Preprocesamiento:**

   * Conversi√≥n de fechas.
   * Agregaci√≥n de m√©tricas por ruta: promedio de llenado y recolectado.
3. **Definici√≥n de etiqueta (target):**

   * `Eficiente` (1): `Tiempo_Duracion <= 100` y `Recolectado >= 0.8`
   * `Ineficiente` (0): caso contrario
4. **Selecci√≥n de features:**

   * `Tiempo_Duracion`
   * `Cantidad_Contenedores`
   * `Porcentaje_Llenado`
   * `Recolectado`
5. **Split Train/Test:** 70% entrenamiento, 30% prueba.
6. **Modelo:** RandomForestClassifier con 100 estimadores.
7. **Evaluaci√≥n:**

   * Accuracy
   * F1-score
   * Classification report
8. **Guardado del modelo:** `public/modelos/modelo_rutas.pkl`

---

## M√©tricas de Evaluaci√≥n

* **Accuracy:** Porcentaje de predicciones correctas sobre el total.
* **F1-score:** Media arm√≥nica entre precisi√≥n y recall.
* **Classification Report:** Desglose de precisi√≥n, recall y F1-score por clase.

---

## Dependencias

* `pandas`
* `numpy`
* `scikit-learn`
* `joblib`
* `fastapi`
* `sqlalchemy`

---

## Uso en FastAPI


Despu√©s de incluir el router, se pueden usar los endpoints `/ml/entrenar/` y `/ml/predecir/`.

---
# Modelo de An√°lisis No Supervisado (ML)

## Objetivo

Implementar un **modelo de an√°lisis no supervisado** sobre los datos de lecturas de sensores para identificar patrones o agrupaciones naturales. En este proyecto se utiliz√≥ **K-Means Clustering** como t√©cnica principal.

---

## Metodolog√≠a

1. **Preparaci√≥n de datos**

   * Se utiliza el CSV generado previamente con todas las lecturas de sensores (`lecturas_todos_sensores.csv`).
   * Columnas consideradas: `Valor`, `Hora`, `DiaSemana`.
   * Se transforma `DiaSemana` a valores num√©ricos (`0=Monday, 6=Sunday`).
   * Se escalan las variables usando `StandardScaler` para que todas tengan la misma importancia en el clustering.

2. **Entrenamiento del modelo**

   * Se utiliza `KMeans` de `sklearn` con n√∫mero de clusters configurable (`n_clusters`).
   * El modelo se ajusta a los datos escalados y se asigna un cluster a cada lectura.
   * El modelo entrenado se guarda en: `datos/modelos/kmeans_model.pkl`.

3. **Generaci√≥n de informe**

   * Se genera un **PDF** que incluye:

     * Silhouette Score para evaluar la calidad del clustering.
     * Gr√°ficos 2D de:

       * Valor vs Hora
       * Valor vs D√≠a de la semana
     * Tabla con los promedios de cada variable por cluster.
     * Interpretaci√≥n autom√°tica en texto para cada cluster, explicando sus caracter√≠sticas de manera comprensible para un usuario com√∫n.

---

## M√©tricas utilizadas

* **Silhouette Score**: Indica qu√© tan separados y compactos est√°n los clusters.

  * Valor cercano a 1: clusters bien definidos.
  * Valor cercano a 0: clusters solapados o poco definidos.
  * Valor negativo: posibles errores en la asignaci√≥n de clusters.

* **Estad√≠sticas por cluster**:

  * Cantidad de lecturas por cluster.
  * Promedio de `Valor`, `Hora` y `DiaSemana_num` por cluster.

---

## Interpretaci√≥n

Cada cluster representa un **patr√≥n de comportamiento de lecturas**. Por ejemplo:

* Cluster 0: lecturas con valores altos en horas pico.
* Cluster 1: lecturas bajas en d√≠as espec√≠ficos de la semana.
* Cluster 2: lecturas promedio distribuidas de manera uniforme.

> Nota: La interpretaci√≥n se genera autom√°ticamente en el PDF para facilitar su comprensi√≥n por cualquier usuario.

---

## Archivos generados

* Modelo entrenado: `public/modelos/kmeans_model.pkl`
* Informe PDF: `public/informe_clusters.pdf`

---

## Uso en FastAPI

Existen endpoints para entrenar el modelo y descargar el PDF:

1. **Entrenar modelo y generar PDF**

```
GET /ml_unsupervised/entrenar/?n_clusters=3
```

2. **Descargar PDF**

```
GET /ml_unsupervised/descargar-informe/
```

---

## Bibliotecas utilizadas

* `pandas`
* `matplotlib`
* `sklearn` (`KMeans`, `StandardScaler`, `silhouette_score`)
* `joblib`
* `reportlab`

# üìä Modelo de Data Warehouse
---

En esta fase se dise√±√≥ el **Modelo de Data Warehouse** del proyecto **SmartWasteApi**, siguiendo un **esquema en estrella** para facilitar la integraci√≥n, consulta y an√°lisis de la informaci√≥n hist√≥rica de las lecturas de los sensores de residuos.

---

## üèóÔ∏è Esquema en Estrella

El modelo se compone de una **tabla de hechos central** (`Fact_Lecturas`) y varias **tablas de dimensiones** relacionadas.  

### üîπ Tabla de Hechos: `Fact_Lecturas`
Contiene los datos medibles del sistema, provenientes de las lecturas de los sensores.

| Campo          | Tipo        | Descripci√≥n |
|----------------|------------|-------------|
| **Lectura_ID** | INT (PK)   | Identificador √∫nico de la lectura |
| **Sensor_Id**  | INT (FK)   | Clave for√°nea hacia `Dim_Sensor` |
| **Contenedor_Id** | INT (FK) | Clave for√°nea hacia `Dim_Contenedor` |
| **Ruta_Id**    | INT (FK)   | Clave for√°nea hacia `Dim_Ruta` |
| **Tiempo_ID**  | INT (FK)   | Clave for√°nea hacia `Dim_Tiempo` |
| **Valor**      | FLOAT      | Medici√≥n registrada (nivel de llenado del contenedor en %) |

---

### üîπ Dimensiones

#### `Dim_Sensor`
Informaci√≥n sobre los sensores que capturan las lecturas.

| Campo       | Tipo        | Descripci√≥n |
|-------------|------------|-------------|
| **Sensor_Id** | INT (PK) | Identificador √∫nico del sensor |
| Tipo        | VARCHAR    | Tipo de sensor (ultras√≥nico, presi√≥n, etc.) |
| Modelo      | VARCHAR    | Modelo o referencia del fabricante |

---

#### `Dim_Contenedor`
Describe los contenedores de residuos.

| Campo             | Tipo        | Descripci√≥n |
|-------------------|------------|-------------|
| **Contenedor_Id** | INT (PK)   | Identificador √∫nico del contenedor |
| Ubicacion         | VARCHAR    | Direcci√≥n o zona del contenedor |
| Capacidad         | FLOAT      | Capacidad m√°xima en litros |

---

#### `Dim_Ruta`
Informaci√≥n sobre las rutas de recolecci√≥n.

| Campo        | Tipo        | Descripci√≥n |
|--------------|------------|-------------|
| **Ruta_Id**  | INT (PK)   | Identificador √∫nico de la ruta |
| Nombre       | VARCHAR    | Nombre de la ruta |
| Descripci√≥n  | VARCHAR    | Observaciones adicionales |

---

#### `Dim_Tiempo`
Dimensi√≥n temporal para an√°lisis hist√≥rico.

| Campo         | Tipo        | Descripci√≥n |
|---------------|------------|-------------|
| **Tiempo_ID** | INT (PK)   | Identificador √∫nico del tiempo |
| Fecha         | DATE       | Fecha de la lectura |
| Hora          | TIME       | Hora de la lectura |
| Dia           | INT        | D√≠a del mes |
| Mes           | INT        | Mes |
| A√±o           | INT        | A√±o |
| DiaSemana     | VARCHAR    | Nombre del d√≠a (Lunes, Martes, etc.) |

---

## üìê Jerarqu√≠as Definidas

1. **Tiempo** ‚Üí A√±o > Mes > D√≠a > Hora  
2. **Ruta** ‚Üí Ruta > Contenedor > Sensor  

Estas jerarqu√≠as permiten realizar an√°lisis agregados por periodo, ubicaci√≥n y dispositivo.

---

## üìë Metadatos

- **Grano del Data Warehouse**: Cada registro en `Fact_Lecturas` representa una **lectura puntual de un sensor en un contenedor en un instante de tiempo espec√≠fico**.  
- **Integraci√≥n**: Las dimensiones se mantienen independientes para permitir la extensibilidad del modelo (por ejemplo, agregar nuevas rutas o sensores sin redise√±ar el esquema).  
- **Optimizaci√≥n**: El esquema en estrella se eligi√≥ por su simplicidad y eficiencia para consultas OLAP.  

---

‚úÖ Con este modelo, el Data Warehouse soporta an√°lisis de llenado de contenedores, eficiencia de rutas y comportamiento temporal de los residuos.

# üìä Visualizaci√≥n y Dashboard

## üìù Descripci√≥n
En este m√≥dulo se implement√≥ un **dashboard interactivo** utilizando **Streamlit** y **Plotly**, con el objetivo de analizar los datos de:
- **Bit√°cora de Recolecci√≥n**
- **Bit√°cora de Contenedores**
- **Lecturas de Sensores**

La visualizaci√≥n permite al usuario explorar, comparar y detectar patrones clave en las operaciones del sistema de recolecci√≥n de residuos inteligentes.

---

## üéØ Objetivo
- Facilitar el **an√°lisis visual** de los datos recolectados.
- Identificar **tendencias y anomal√≠as** en los tiempos de recolecci√≥n, llenado de contenedores y lecturas de sensores.
- Apoyar la **toma de decisiones** en la planeaci√≥n de rutas y mantenimiento de contenedores.

---

## ‚öôÔ∏è Herramientas utilizadas
- **Streamlit** ‚Üí Framework para construir el dashboard interactivo.  
- **Plotly Express** ‚Üí Librer√≠a de visualizaci√≥n interactiva para gr√°ficos din√°micos.  
- **Pandas** ‚Üí Manipulaci√≥n y limpieza de datos antes de la visualizaci√≥n.  

---

## üìÇ Estructura de Archivos
dashboard/
‚îÇ‚îÄ‚îÄ dashboard.py # C√≥digo principal del dashboard
‚îÇ‚îÄ‚îÄ datos/
‚îú‚îÄ‚îÄ bitacora_recoleccion_etl.csv
‚îú‚îÄ‚îÄ bitacora_contenedor_etl.csv
‚îú‚îÄ‚îÄ lecturas_todos_sensores.csv

---

## üì∫ Visualizaciones Implementadas

### 1. üì¶ Bit√°cora de Contenedores
- **Histograma del porcentaje de llenado** ‚Üí distribuciones por rango.  
- **Tendencias temporales** ‚Üí evoluci√≥n del llenado por fecha.  
- **Boxplot por estado del contenedor** ‚Üí identificaci√≥n de outliers.  

### 2. üöõ Bit√°cora de Recolecci√≥n
- **Duraci√≥n promedio de rutas** ‚Üí an√°lisis de eficiencia.  
- **Cantidad de contenedores recolectados por ruta** ‚Üí carga de trabajo.  
- **Comparaci√≥n de observaciones** ‚Üí patrones de incidencias.  

### 3. üì° Lecturas de Sensores
- **Serie temporal de valores por sensor** ‚Üí evoluci√≥n en el tiempo.  
- **Promedios por d√≠a de la semana** ‚Üí patrones de llenado seg√∫n d√≠as.  
- **Boxplot por hora del d√≠a** ‚Üí valores at√≠picos y tendencias horarias.  

---

## üìñ Storytelling y An√°lisis Visual
1. **Contenedores cr√≠ticos** ‚Üí Se observ√≥ que los contenedores da√±ados presentan valores extremos en porcentaje de llenado.  
2. **Rutas eficientes vs. ineficientes** ‚Üí Al comparar tiempos de duraci√≥n y cantidad de contenedores, se identifican rutas m√°s √≥ptimas.  
3. **Patrones semanales** ‚Üí Los sensores muestran mayor porcentaje de llenado a inicios de semana (lunes y martes), lo que sugiere ajustar la planeaci√≥n.  
4. **Anomal√≠as detectadas** ‚Üí Boxplots de sensores ayudan a identificar lecturas fuera de rango (ej. > 100%), que corresponden a fallas o datos at√≠picos.  

---

## üöÄ Ejecuci√≥n del Dashboard
Para iniciar el dashboard localmente:
```bash
streamlit run dashboard/dashboard.py
```
Esto abrir√° autom√°ticamente en el navegador:
üëâ http://localhost:8501
 ---
 ## pruevas de regresion
Para iniciar pruebas en los endpoints principales ejecute:
```bash
python -m pytest -v --import-mode=importlib
```


**Proyecto:** SmartWasteApi

